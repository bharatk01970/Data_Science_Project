# CSV Dictionary Field Processor
## Professional Documentation Package

---

# Document 1: Executive Summary

## Overview
The **CSV Dictionary Field Processor** is a sophisticated data transformation tool designed to handle complex CSV files containing dictionary-like fields with nested key-value pairs and multi-valued entries. The tool employs a two-stage processing architecture to provide maximum flexibility and control over data extraction and mapping operations.

## Key Capabilities

### 🎯 Core Utilities

1. **Dictionary Field Expansion**
   - Automatically detects fields containing dictionary-like data structures
   - Extracts nested key-value pairs into separate columns
   - Handles multiple formats: JSON, Python dictionaries, newline-separated pairs

2. **Duplicate Key Handling**
   - Preserves ALL values when dictionary keys appear multiple times
   - No data loss - captures every occurrence
   - Generates Cartesian product of all combinations

3. **Multi-Value Splitting**
   - Splits comma-separated and semicolon-separated values
   - Creates individual rows for each value combination
   - Maintains data integrity through deduplication

4. **Universal Encoding Support**
   - Automatically detects file encoding (UTF-8, UTF-16, Latin-1, etc.)
   - Eliminates encoding-related errors
   - Supports international character sets

5. **Data Mapping Integration**
   - Maps processed data against external reference files
   - Enriches output with additional columns
   - Uses original column names from mapping files

6. **Two-Stage Processing**
   - Stage 1: Dictionary expansion and multi-value splitting
   - Stage 2: Mapping application and final output generation
   - Clear separation enables iterative refinement

## Business Value

### ✅ Time Savings
- **Manual Processing:** Hours to days
- **With Tool:** Minutes
- **Efficiency Gain:** 95%+

### ✅ Data Accuracy
- Zero data loss from duplicate keys
- Automatic deduplication
- Consistent transformation logic

### ✅ Flexibility
- User controls which fields to process
- Selective key extraction from dictionaries
- Optional mapping for data enrichment

### ✅ Scalability
- Handles files with thousands of rows
- Processes multiple dictionary fields simultaneously
- Cartesian product generation for all combinations

## Target Use Cases

1. **Data Migration Projects**
   - Transform legacy data formats
   - Extract nested information
   - Prepare data for new systems

2. **Data Enrichment**
   - Add reference data from mapping files
   - Expand abbreviated codes
   - Enhance data completeness

3. **Report Generation**
   - Flatten complex nested structures
   - Create analysis-ready datasets
   - Generate comprehensive reports

4. **Data Quality Improvement**
   - Standardize multi-valued fields
   - Extract all information from text fields
   - Ensure completeness through duplicate handling

## Technical Specifications

- **Language:** Python 3.7+
- **Framework:** Tkinter (GUI)
- **Dependencies:** pandas, chardet, json, ast
- **Platform:** Windows, macOS, Linux
- **File Support:** CSV, TXT (tab-delimited)
- **Export Formats:** CSV, Excel (.xlsx)

---

# Document 2: User Manual & Standard Operating Procedure (SOP)

## Installation Instructions

### Prerequisites
```bash
# Required Python packages
pip install pandas
pip install chardet
pip install openpyxl  # For Excel export
```

### Running the Tool
```bash
# Navigate to tool directory
cd /path/to/tool

# Run the application
python csv_processor.py
```

## Standard Operating Procedure (SOP)

### Stage 1: File Loading and Field Selection

#### Step 1.1: Load Input File
1. Click **"Select Input File"** button
2. Navigate to your CSV/TXT file
3. Click **"Open"**
4. Verify status message shows correct row/column count and encoding

**Success Indicator:**
- Status bar shows: "Loaded file with X rows and Y columns (encoding: utf-8)"
- Field list populates with all column names

**Troubleshooting:**
- If file fails to load, check file format (must be CSV or tab-delimited TXT)
- Ensure file is not open in another application
- Verify file is not corrupted

---

#### Step 1.2: Select Fields for Processing
1. Review the field list (Section 3)
2. Click on fields you want to process
3. Use **Ctrl+Click** (Windows/Linux) or **Cmd+Click** (Mac) for multiple selections
4. Use **Shift+Click** to select a range

**Best Practices:**
- Select only fields that need processing (reduces processing time)
- Include fields with dictionary-like content
- Include fields with multi-valued entries
- Include fields needed for mapping operations

**Example Selection:**
```
✓ ID
✓ Name
✓ ContactDetails  (dictionary field)
✓ Skills          (multi-valued field)
✗ CreatedDate     (exclude if not needed)
✗ Notes           (exclude if not needed)
```

---

### Stage 2: Stage 1 Processing (Dictionary Expansion)

#### Step 2.1: Initiate Stage 1
1. After selecting fields, click **"Process Stage 1 (Dictionary Expansion)"**
2. Tool automatically detects dictionary-like fields
3. For each dictionary field detected, a popup appears

**What Happens:**
- Tool scans selected fields for dictionary patterns
- Identifies fields with key-value pairs (format: `key: value` or `key = value`)
- Detects JSON-formatted dictionaries: `{"key": "value"}`

---

#### Step 2.2: Dictionary Key Selection
When a dictionary field is detected:

**Popup Appearance:**
```
┌─────────────────────────────────────────┐
│ Select keys to include from field       │
│ 'ContactDetails':                       │
│ Tip: Click on keys to select them.     │
│      Hold Ctrl/Cmd to select multiple. │
│                                         │
│ ┌─────────────────────────────────────┐ │
│ │ ☐ Email                             │ │
│ │ ☐ Phone                             │ │
│ │ ☐ Address                           │ │
│ │ ☐ City                              │ │
│ │ ☐ State                             │ │
│ │ ☐ ZIP                               │ │
│ └─────────────────────────────────────┘ │
│                                         │
│        0 of 6 keys selected             │
│                                         │
│    [Select All]    [Clear All]          │
│                                         │
│  [Confirm Selection]    [Cancel]        │
└─────────────────────────────────────────┘
```

**Actions:**
1. **Manual Selection:** Click on individual keys you want to extract
   - Selection counter updates in real-time
   - Hold Ctrl/Cmd to select multiple

2. **Select All:** Click to select all available keys quickly

3. **Clear All:** Click to deselect all and start over

4. **Confirm Selection:** Click to proceed with selected keys

5. **Cancel:** Click to skip this dictionary field

**Important Notes:**
- **Nothing is pre-selected** - you must manually choose keys
- Select only keys you need in the final output
- More keys = more output rows (Cartesian product)
- Selection counter shows "X of Y keys selected"

**Example Selection Strategy:**
```
From ContactDetails field with 10 keys:
✓ Email    (select - needed)
✓ Phone    (select - needed)
✓ City     (select - needed)
✗ Notes    (skip - not needed)
✗ Internal (skip - internal use only)
✗ Temp1    (skip - temporary data)
```

---

#### Step 2.3: Complete Stage 1
1. After all dictionary fields are processed, Stage 1 executes
2. Status label shows: **"✓ Complete (X rows)"**
3. Status bar updates with row count
4. Mapping and Stage 2 buttons become enabled

**Success Indicators:**
- Green checkmark appears next to Stage 1 button
- Status shows number of rows generated
- "Add Mapping File" button is now enabled
- "Process Stage 2" button is now enabled

**What Happened:**
- Dictionary fields expanded into separate columns (e.g., `ContactDetails_Email`)
- Multi-valued fields split into separate rows
- Cartesian product generated for all combinations
- Duplicate values removed

---

### Stage 3: Mapping File Addition (Optional)

#### Step 3.1: When to Use Mapping
Use mapping files when you need to:
- Add descriptive names for codes/IDs
- Enrich data with additional information
- Translate values to standard formats
- Add reference data from external sources

**Example Scenario:**
```
Your data has:        You want to add:
ID: EMP001           → Name: John Smith
ID: EMP002           → Name: Jane Doe

Mapping File Structure:
EMP001, John Smith
EMP002, Jane Doe
```

---

#### Step 3.2: Add Mapping Files
1. Click **"Add Mapping File"** button
2. Select your mapping CSV/TXT file
3. Tool automatically detects common columns
4. If multiple matches found, choose the correct field
5. Mapping appears in the listbox

**Mapping File Requirements:**
- Must have at least 2 columns
- First column: Key (matches value in your data)
- Second column: Value (will be added to output)
- Can use CSV or tab-delimited format

**Example Mapping File:**
```csv
EmployeeID,EmployeeName
EMP001,John Smith
EMP002,Jane Doe
EMP003,Bob Johnson
```

**Auto-Detection:**
- Tool compares Stage 1 output columns with mapping file columns
- Automatically suggests matching field
- If multiple matches, prompts you to choose

**Adding Multiple Mappings:**
- Click "Add Mapping File" again for additional mappings
- Each mapping appears in the listbox
- Can map different fields using different files

---

### Stage 4: Stage 2 Processing (Final Output)

#### Step 4.1: Execute Stage 2
1. Click **"Process Stage 2 (Final Output with Mapping)"**
2. Tool applies all loaded mappings
3. Generates final processed dataset
4. Export button becomes enabled

**What Happens:**
- Takes Stage 1 output as input
- Applies each mapping file
- Adds new columns with original names from mapping files
- Preserves all existing columns
- Generates complete final dataset

**Column Naming:**
- Original fields: Keep their names (e.g., `ID`, `Name`)
- Expanded dictionary keys: `FieldName_KeyName` (e.g., `ContactDetails_Email`)
- Mapped fields: Use column name from mapping file (e.g., `EmployeeName`)

---

### Stage 5: Export Results

#### Step 5.1: Export Data
1. Click **"Export Results"** button
2. Choose save location and filename
3. Select format: CSV (.csv) or Excel (.xlsx)
4. Click **"Save"**

**Export Options:**
- **CSV Format:** Compatible with all systems, smaller file size
- **Excel Format:** Better formatting, supports multiple sheets

**Success Confirmation:**
- Popup appears: "Data exported successfully"
- Status bar shows: "Data exported to [filename]"

---

#### Step 5.2: Post-Export Options
After export, a completion popup appears:

**Options:**
1. **Continue Working:** Return to tool for additional processing
2. **Close Application:** Exit the tool

**Best Practice:**
- Choose "Continue Working" if you want to:
  - Export in different format
  - Process another file
  - Try different field selections

---

## Data Processing Examples

### Example 1: Simple Dictionary Expansion

**Input Data:**
```csv
ID,Name,Details
1,John,"Email: john@email.com
Phone: 555-1234
City: New York"
2,Jane,"Email: jane@email.com
Phone: 555-5678
City: Boston"
```

**Selected Fields:** ID, Name, Details

**Stage 1 - Key Selection for "Details":**
- Select: Email, Phone, City

**Stage 1 Output:**
```csv
ID,Name,Details_Email,Details_Phone,Details_City
1,John,john@email.com,555-1234,New York
2,Jane,jane@email.com,555-5678,Boston
```

---

### Example 2: Multi-Value Expansion

**Input Data:**
```csv
ID,Name,Skills
1,John,"Python, SQL, Java"
2,Jane,"Python, R, Excel"
```

**Selected Fields:** ID, Name, Skills

**Stage 1 Output:**
```csv
ID,Name,Skills
1,John,Python
1,John,SQL
1,John,Java
2,Jane,Python
2,Jane,R
2,Jane,Excel
```

---

### Example 3: Dictionary with Duplicate Keys

**Input Data:**
```csv
ID,Name,Contacts
1,John,"Phone: 555-1234
Phone: 555-5678
Email: john@email.com
Phone: 555-9999"
```

**Selected Fields:** ID, Name, Contacts

**Stage 1 - Key Selection for "Contacts":**
- Select: Phone, Email

**Stage 1 Output (Cartesian Product):**
```csv
ID,Name,Contacts_Phone,Contacts_Email
1,John,555-1234,john@email.com
1,John,555-5678,john@email.com
1,John,555-9999,john@email.com
```

**All 3 phone numbers preserved!**

---

### Example 4: Combined Processing with Mapping

**Input Data:**
```csv
EmpID,ContactInfo
E001,"Email: john@co.com
Phone: 555-1234"
E002,"Email: jane@co.com
Phone: 555-5678"
```

**Mapping File (employees.csv):**
```csv
EmpID,EmployeeName,Department
E001,John Smith,Engineering
E002,Jane Doe,Marketing
```

**Stage 1 Processing:**
- Select: EmpID, ContactInfo
- Extract: Email, Phone

**Stage 1 Output:**
```csv
EmpID,ContactInfo_Email,ContactInfo_Phone
E001,john@co.com,555-1234
E002,jane@co.com,555-5678
```

**Stage 2 Processing:**
- Add mapping file: employees.csv
- Map on: EmpID

**Final Output:**
```csv
EmpID,ContactInfo_Email,ContactInfo_Phone,EmployeeName,Department
E001,john@co.com,555-1234,John Smith,Engineering
E002,jane@co.com,555-5678,Jane Doe,Marketing
```

---

## Troubleshooting Guide

### Issue 1: File Won't Load
**Symptoms:** Error message when selecting file

**Solutions:**
1. Check file format (CSV or tab-delimited TXT only)
2. Close file if open in Excel or other programs
3. Verify file is not corrupted
4. Try saving file with UTF-8 encoding
5. Check file has proper headers

---

### Issue 2: No Dictionary Fields Detected
**Symptoms:** Stage 1 completes but no popups appear

**Causes:**
- Selected fields don't contain dictionary-like data
- Dictionary format not recognized

**Solutions:**
1. Verify field contains key-value pairs (format: `key: value` or `key = value`)
2. Check for JSON format: `{"key": "value"}`
3. Ensure field is selected in field list
4. Review sample data to confirm structure

---

### Issue 3: Too Many Output Rows
**Symptoms:** Stage 1 generates thousands/millions of rows

**Cause:** Cartesian product of multi-valued fields

**Solution:**
1. Review selected dictionary keys (fewer keys = fewer rows)
2. Consider processing fields separately
3. Pre-filter input data to remove unnecessary values
4. Use more selective field selection

**Example:**
```
3 fields with 10 values each = 10 × 10 × 10 = 1,000 rows
Reduce to: 3 fields with 5 values each = 5 × 5 × 5 = 125 rows
```

---

### Issue 4: Mapping Not Working
**Symptoms:** Stage 2 completes but no new columns added

**Solutions:**
1. Verify mapping file has matching column name with Stage 1 output
2. Check mapping file has at least 2 columns
3. Ensure values in mapping file match exactly (case-sensitive)
4. Confirm mapping file loaded successfully (check listbox)

---

### Issue 5: Special Characters Display Incorrectly
**Symptoms:** Foreign characters or symbols show as ??? or boxes

**Solution:**
- Tool automatically detects encoding
- If issues persist, save file as UTF-8 before loading

---

## Best Practices

### ✅ Before Processing
1. **Backup original data** - Always keep original file safe
2. **Review data structure** - Understand your dictionary fields
3. **Plan output** - Know which fields and keys you need
4. **Prepare mapping files** - Have reference data ready

### ✅ During Processing
1. **Select strategically** - Choose only necessary fields
2. **Review key selection** - Don't select everything blindly
3. **Monitor row count** - Watch for Cartesian explosion
4. **Test with sample** - Process small subset first

### ✅ After Processing
1. **Verify output** - Check row counts and data integrity
2. **Review new columns** - Ensure expansions are correct
3. **Validate mappings** - Confirm mapped data is accurate
4. **Document process** - Note selections and mappings used

---

## Performance Guidelines

### File Size Recommendations
- **Small (< 1,000 rows):** Instant processing
- **Medium (1,000 - 10,000 rows):** Seconds to process
- **Large (10,000 - 100,000 rows):** 1-2 minutes
- **Very Large (> 100,000 rows):** Consider splitting file

### Optimization Tips
1. Select fewer fields when possible
2. Extract only necessary dictionary keys
3. Process in stages for very large files
4. Use CSV export for faster performance
5. Close other applications during processing

---

# Document 3: Technical Workflow & Algorithm

## System Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     CSV PROCESSOR TOOL                       │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌────────────────────────────────────────────────────┐    │
│  │              INPUT LAYER                            │    │
│  │  • File Selection (CSV/TXT)                        │    │
│  │  • Encoding Detection (chardet)                    │    │
│  │  • DataFrame Loading (pandas)                      │    │
│  └────────────────────────────────────────────────────┘    │
│                          ↓                                   │
│  ┌────────────────────────────────────────────────────┐    │
│  │         FIELD SELECTION LAYER                       │    │
│  │  • User selects fields for processing              │    │
│  │  • Multi-selection support                         │    │
│  └────────────────────────────────────────────────────┘    │
│                          ↓                                   │
│  ┌────────────────────────────────────────────────────┐    │
│  │          STAGE 1: EXPANSION LAYER                   │    │
│  │                                                     │    │
│  │  ┌──────────────────────────────────────────────┐ │    │
│  │  │  Dictionary Field Detection                  │ │    │
│  │  │  • Pattern matching (key:value, key=value)  │ │    │
│  │  │  • JSON detection                            │ │    │
│  │  │  • Key extraction                            │ │    │
│  │  └──────────────────────────────────────────────┘ │    │
│  │                    ↓                                │    │
│  │  ┌──────────────────────────────────────────────┐ │    │
│  │  │  User Key Selection                          │ │    │
│  │  │  • Interactive popup                         │ │    │
│  │  │  • Manual selection (no pre-selection)       │ │    │
│  │  │  • Real-time counter                         │ │    │
│  │  └──────────────────────────────────────────────┘ │    │
│  │                    ↓                                │    │
│  │  ┌──────────────────────────────────────────────┐ │    │
│  │  │  Data Transformation Engine                  │ │    │
│  │  │  • Parse dictionary values                   │ │    │
│  │  │  • Handle duplicate keys → lists            │ │    │
│  │  │  • Split multi-values (comma/semicolon)     │ │    │
│  │  │  • Generate Cartesian product               │ │    │
│  │  │  • Deduplicate results                       │ │    │
│  │  └──────────────────────────────────────────────┘ │    │
│  │                    ↓                                │    │
│  │         Stage 1 Output (Intermediate Data)          │    │
│  └────────────────────────────────────────────────────┘    │
│                          ↓                                   │
│  ┌────────────────────────────────────────────────────┐    │
│  │         MAPPING LAYER (Optional)                    │    │
│  │  • Load external mapping files                     │    │
│  │  • Auto-detect common columns                      │    │
│  │  • Store mapping relationships                     │    │
│  └────────────────────────────────────────────────────┘    │
│                          ↓                                   │
│  ┌────────────────────────────────────────────────────┐    │
│  │          STAGE 2: MAPPING LAYER                     │    │
│  │  • Apply mappings to Stage 1 data                  │    │
│  │  • Add new columns with original names             │    │
│  │  • Preserve existing columns                       │    │
│  └────────────────────────────────────────────────────┘    │
│                          ↓                                   │
│  ┌────────────────────────────────────────────────────┐    │
│  │              OUTPUT LAYER                           │    │
│  │  • Export to CSV or Excel                          │    │
│  │  • User confirmation                               │    │
│  └────────────────────────────────────────────────────┘    │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

---

## Core Algorithms

### Algorithm 1: Dictionary Field Detection

```
FUNCTION detect_dictionary_fields(selected_fields):
    dict_fields = {}
    
    FOR each field IN selected_fields:
        IF field exists in dataframe:
            sample = first 10 non-null values from field
            dict_count = 0
            all_keys = empty set
            
            FOR each value IN sample:
                IF is_dictionary_like(value):
                    dict_count++
                    parsed = parse_dictionary_value(value)
                    all_keys.add(keys from parsed)
            
            IF dict_count > 50% of sample size:
                dict_fields[field] = list(all_keys)
    
    RETURN dict_fields

FUNCTION is_dictionary_like(value):
    TRY:
        IF value is NA or empty:
            RETURN False
        
        value_str = convert to string
        
        IF value_str starts with '{' and ends with '}':
            RETURN True
        
        IF value_str contains ':' or '=':
            RETURN True
        
        RETURN False
    CATCH any error:
        RETURN False
```

---

### Algorithm 2: Dictionary Value Parsing with Duplicate Key Support

```
FUNCTION parse_dictionary_value(value):
    TRY:
        IF value is NA or empty:
            RETURN empty dict
    CATCH ValueError, TypeError:
        RETURN empty dict
    
    value_str = convert to string
    result = {}
    
    # Method 1: Try JSON parsing
    TRY:
        IF value_str is JSON format:
            parsed = json.loads(value_str)
            FOR each key, val IN parsed:
                result[key] = [val]  # Store as list
            RETURN result
    CATCH:
        pass
    
    # Method 2: Try Python literal evaluation
    TRY:
        parsed = ast.literal_eval(value_str)
        IF parsed is dict:
            FOR each key, val IN parsed:
                result[key] = [val]  # Store as list
            RETURN result
    CATCH:
        pass
    
    # Method 3: Manual parsing with duplicate support
    TRY:
        lines = split value_str by newline, filter empty
        
        FOR each line IN lines:
            IF line contains ':':
                key, val = split on first ':'
                IF key already exists in result:
                    result[key].append(val)  # Append to list
                ELSE:
                    result[key] = [val]      # Create new list
            
            ELSE IF line contains '=':
                key, val = split on first '='
                IF key already exists in result:
                    result[key].append(val)
                ELSE:
                    result[key] = [val]
    CATCH:
        pass
    
    RETURN result
```

**Key Innovation:** Dictionary values stored as lists to preserve duplicate keys

---

### Algorithm 3: Single Row Processing with Cartesian Product

```
FUNCTION process_single_row(row, result_rows):
    field_expansions = {}
    
    # Process regular (non-dictionary) fields
    FOR each field IN selected_fields:
        IF field is NOT dictionary field:
            TRY:
                field_value = row[field]
            CATCH KeyError, TypeError:
                field_value = ""
            
            values = split_multi_values(field_value)
            unique_values = remove_duplicates(values)
            IF unique_values is empty:
                unique_values = [""]
            
            field_expansions[field] = unique_values
    
    # Process dictionary fields with duplicate key support
    FOR each field IN dictionary_fields:
        IF field IN selected_keys:
            TRY:
                dict_value = row[field]
            CATCH KeyError, TypeError:
                dict_value = ""
            
            parsed_dict = parse_dictionary_value(dict_value)
            
            FOR each key IN selected_keys[field]:
                IF key IN parsed_dict:
                    all_key_values = []
                    
                    # Iterate through all values (list)
                    FOR each val IN parsed_dict[key]:
                        IF val is None:
                            val = ""
                        split_values = split_multi_values(val)
                        all_key_values.extend(split_values)
                    
                    unique_values = remove_duplicates(all_key_values)
                    IF unique_values is empty:
                        unique_values = [""]
                    
                    field_expansions[field + "_" + key] = unique_values
                ELSE:
                    field_expansions[field + "_" + key] = [""]
    
    # Generate Cartesian product
    IF field_expansions is not empty:
        field_names = keys of field_expansions
        field_values = values of field_expansions
        
        FOR each combination IN cartesian_product(field_values):
            new_row = {}
            FOR each field_name, value IN zip(field_names, combination):
                new_row[field_name] = value
            
            IF new_row not in result_rows:
                result_rows.append(new_row)
```

**Cartesian Product Example:**
```
Field A: [1, 2]
Field B: [X, Y, Z]

Output Combinations:
(1, X), (1, Y), (1, Z), (2, X), (2, Y), (2, Z)

= 2 × 3 = 6 rows
```

---

### Algorithm 4: Multi-Value Splitting

```
FUNCTION split_multi_values(value):
    TRY:
        IF value is NA or None or empty:
            RETURN [""]
    CATCH:
        RETURN [""]
    
    value_str = convert to string and trim
    
    IF value_str is empty after trim:
        RETURN [""]
    
    IF value_str contains ';':
        values = split by ';' and trim each
        RETURN filter_empty(values)
    
    ELSE IF value_str contains ',':
        values = split by ',' and trim each
        RETURN filter_empty(values)
    
    ELSE:
        RETURN [value_str]
```

**Separator Priority:**
1. Semicolon (`;`) - Higher priority
2. Comma (`,`) - Lower priority
3. No separator - Single value

---

### Algorithm 5: Mapping Application

```
FUNCTION apply_mappings(result_rows):
    FOR each field, mapping_df IN mapping_data:
        IF field IN selected_fields:
            IF mapping_df has at least 2 columns:
                key_col = first column of mapping_df
                value_col = second column of mapping_df
                
                # Create lookup dictionary
                mapping_dict = create dict from (key_col, value_col)
                
                FOR each row IN result_rows:
                    IF field exists in row:
                        mapped_value = lookup in mapping_dict[row[field]]
                        IF not found:
                            mapped_value = ""
                        
                        # Use original column name from mapping file
                        row[value_col] = mapped_value
    
    RETURN result_rows
```

**Mapping Example:**
```
Mapping File Columns: [EmployeeID, EmployeeName]
Input Row: {EmployeeID: "E001", ...}
Mapping: E001 → John Smith
Output Row: {EmployeeID: "E001", EmployeeName: "John Smith", ...}
                                   ↑ Original column name used
```

---

## Data Flow Diagram

```
┌─────────────┐
│ Input File  │
│  (CSV/TXT)  │
└──────┬──────┘
       │
       ↓ [Encoding Detection]
┌──────────────┐
│  DataFrame   │
│   (pandas)   │
└──────┬───────┘
       │
       ↓ [User Selection]
┌──────────────────┐
│ Selected Fields  │
│ [F1, F2, F3]     │
└──────┬───────────┘
       │
       ↓ [Dictionary Detection]
┌────────────────────────┐
│ Dictionary Fields      │
│ F2: [Key1, Key2, Key3] │
└──────┬─────────────────┘
       │
       ↓ [User Key Selection Popup]
┌────────────────────────┐
│ Selected Keys          │
│ F2: [Key1, Key3]       │
└──────┬─────────────────┘
       │
       ↓ [Row-by-Row Processing]
       ↓
┌──────────────────────────────┐
│  For Each Row:               │
│  1. Parse dictionaries       │
│  2. Extract selected keys    │
│  3. Split multi-values       │
│  4. Generate combinations    │
│  5. Create output rows       │
└──────┬───────────────────────┘
       │
       ↓ [Deduplication]
┌──────────────────┐
│  Stage 1 Output  │
│  (Intermediate)  │
└──────┬───────────┘
       │
       ├────→ [Optional: Add Mapping Files]
       │      ↓
       │   ┌──────────────────┐
       │   │ Mapping Files    │
       │   │ [